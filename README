
I have also created a full stack application out of this project which uses flask as backend and react as frontend and it is hosted on AWS. You can check it out at http://ec2-54-88-101-218.compute-1.amazonaws.com:3000/ . If for any reason it is not working, you can check out the video of the application at https://www.youtube.com/watch?v=WlzaQYVNEQM .

How to run project?

1. Open Terminal 
2. Go to project folder
3. Run `pip3 install -r requirements.txt`
4. Run `python3 main.py`

Flow of main script:

This script demonstrates the process of generating simulated microscope and dye images of parasitic microorganisms, compressing the images, and determining if the parasite has cancer using both a slow and a fast method.

1. Import necessary libraries, including custom libraries for image generation, compression, and cancer detection.
2. Generate a base image and create a simulated microscope image and dye image based on the base image.
3. Save the generated images to disk.
4. Convert the microscope and dye images to a compressed format using a quadtree representation.
5. Save the compressed images to disk.
6. Calculate if the parasite has cancer using the slow method:
   a. Load the microscope and dye images.
   b. Calculate the overlap between the images, which represents the dye within the parasite.
   c. Print the results and whether the parasite has cancer based on a threshold.
   d. Measure and print the execution time.
7. Calculate if the parasite has cancer using the fast method:
   a. Load the compressed microscope and dye images.
   b. Extract the images from the compressed format.
   c. Calculate the overlap between the images using the fast method.
   d. Print the results and whether the parasite has cancer based on a threshold.
   e. Measure and print the execution time.

Questions:

1. Come up with efficient data structures to represent both types of images: those generated by the microscope, and those generated by the dye sensor. These need not have the same representation; the only requirement is that they be compact and take as little storage space as possible. Explain why you picked the representation you did for each image type, and if possible estimate how much storage would be taken by the images. What is the worst-case storage size in bytes for each image representation you chose?

Answer: 
I have used QuadTree as the data structure to represent both types of images. Quadtree is a tree data structure used primarily for image representation and spatial indexing. They are used for several reasons:

    1. Efficient compression: Quadtrees are effective for compressing images with large areas of uniform color or intensity. By dividing the image into smaller sub-regions and only storing the information about non-uniform regions, quadtrees can store images using less memory than a full grid representation.

    2. Fast spatial queries: Quadtrees enable fast spatial queries, such as searching for points within a specific region or finding the nearest neighbor. Due to their hierarchical structure, quadtrees can quickly eliminate irrelevant parts of the image, speeding up search operations.

    3. Adaptive resolution: Quadtrees allow for adaptive resolution representation of images, where different parts of the image can have different levels of detail. This can be useful when certain regions of the image require higher precision or when working with large datasets that cannot be entirely loaded into memory.

    4. Simplification and filtering: Quadtrees can be used to simplify or filter an image by merging similar regions or by removing small, isolated regions.

Size of images before compression using RGB mode: 10000x10000x3 = 300000000 bytes or 300 MB
Size after using '1' mode which reduced it by 24 times: 300000000/24 = 12500000 bytes or 12.5 MB
Size of images after compression reduced drastically. For instance, the microscope image is reduced to around 90~ KB and the dye image is reduced to around 2.5~ MB. Dye image is larger due to dispersed behavior of dye molecules.

Worst case storage size in bytes for each image representation:
    1. Microscope image: (10000x10000x3)/24 = 12500000 bytes or 12.5 MB
    2. Dye image: (10000x10000x3)/24 = 12500000 bytes or 12.5 MB

But it is very unlikely because the microscope image will definitely consist black pixels together for parasite and dye will be also mostly spread near parasite. So, the worst case storage size in bytes for each image representation will be O(Image Size ^ 2).

2. Before the researchers give you real images to work with, you would like to test out any code you write. To this end, you would like to create “fake” simulated images and pretend they were captured by the microscope and the dye sensor. Using the data structures you chose in (1) above, write code to create such simulated images. Try and be as realistic in the generated images as possible.

Answer:
I am generating fake microscope and dye images using 'fake_image_generator.py'. I am also keeping in mind that only 0.1% of parasite will have cancer (Please refer to the code for more details). I was little confused by the text written in given pdf. It says that the dye molecules are dispersed in the parasite. But, I think it should be dispersed in the medium. So, I have created two functions to create dye image. One with dots and other with lines.
Another approach I tried using is to generate image using Stable Diffusion model but it only generate maximun of 1024x1024 image. So, I have not used it in the final code.

3. Using the simulated images generated by the code you wrote for (2) above as input, write a function to compute whether a parasite has cancer or not.

Answer:
I have written two different algorithm to check that parasite have cancer or not. You can try it out by instructions given in README file.

4. You give your code from (3) to the researchers, who run it and find that it is running too slowly for their liking. What can you do to improve the execution speed? Write the code to implement the fastest possible version you can think of for the function in (3).

Answer:
I had written three different algorithm to check that parasite have cancer or not. 
    1. Slow method: I have used brute force approach to check the overlap between the images. I have used nested for loops to check the overlap. This method is very slow. 
    2. Fast method: I have used quadtree representation to store the images. I have compared it in a divide and conquer approach. I have divided the images into four parts and compared them. If the images are same, then I have added the area of the image to the total overlap. If the images are different, then I have divided the images into four parts and compared them again. This method is very fast.
    3. Faster method: I have cache amount of black pixels in microscope image while it is getting extracted from the compressed format. I have used this cache to calculate the overlap between the images. This method is faster than the fast method.

In code I have used the slow and faster method. As faster method was just an improvement on fast method.

In my trial runs I have found that the faster method is 2-3 times faster than the slow method. I have printed the results and execution time in the terminal. You can try it out by instructions given in README file.

5. What other compression techniques can you suggest for both types of images (parasite and dye)? How would they impact runtime? Can you compute actual runtime and storage costs for typical images (not oversimplified image such as a circle for the parasite, or simple straight lines or random points for dye) in your code? The measurements should be done on your computer with an actual image size of 100,000x100,000 pixels (and not a scaled down version).

Answer: I was'nt able to generate 100k x 100k images as it was taking too much time. But, I have generated 10k x 10k images and compressed them. I have also calculated the storage cost for the compressed images. Other way to compress it can be Run-Length Encoding (RLE).
Run-Length Encoding (RLE) is a lossless compression technique that can be effective for dye sensor images due to the dispersed behavior of dye molecules. RLE represents consecutive data values of the same color as single data values and their counts, which can result in significant storage reduction compared to uncompressed formats, such as the original 100,000x100,000x3 size.

For example, if a dye sensor image has a large area of the same color, RLE can represent this area as a single data value and its count, resulting in a significant reduction in storage. However, if the image has a lot of variation in color, the compression ratio may not be as high.

The estimated storage reduction would depend on the specific characteristics of the image, such as the size of contiguous areas of the same color and the variation in color. However, RLE has been shown to be effective in reducing storage for dye sensor images compared to uncompressed formats.

But estimate storage for a 100k x 100k image which is represented by '1' mode will be around (100kx100kx3)/24 = 1250000000 bytes or 1.25 GB.

6. Describes what tools you used to solve the challenge, particularly any LLM techniques.

Answer: I used Code GPT which uses Ollama to use opesource models like Mitral, Llama and Gemma to generate code. It is opensource alternative to Github Co-pilot. I also used Blackbox.ai agents to get some ideas and tweak my code. I tried to use Stable Diffusion model to generate images but it was not able to generate high quality images. I think it can but would require more time to dig into it.
